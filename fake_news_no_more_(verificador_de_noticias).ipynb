{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/cezarviana/fake-news-no-more/blob/main/fake_news_no_more_(verificador_de_noticias).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%pip -q install google-genai"
      ],
      "metadata": {
        "id": "UCCbECexLk_h"
      },
      "execution_count": 83,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Configura a API Key do Google Gemini\n",
        "\n",
        "import os\n",
        "from google.colab import userdata\n",
        "\n",
        "os.environ[\"GOOGLE_API_KEY\"] = userdata.get('GOOGLE_API_KEY')"
      ],
      "metadata": {
        "id": "NfCqHo1tLk8P"
      },
      "execution_count": 82,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Configura o cliente da SDK do Gemini\n",
        "\n",
        "from google import genai\n",
        "\n",
        "client = genai.Client()\n",
        "\n",
        "MODEL_ID = \"gemini-2.0-flash\""
      ],
      "metadata": {
        "id": "bV4w0H5TLk5g"
      },
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Pergunta ao Gemini uma informação mais recente que seu conhecimento\n",
        "\n",
        "from IPython.display import HTML, Markdown\n",
        "\n",
        "# Perguntar pro modelo quando é a próxima imersão de IA ###############################################\n",
        "resposta = client.models.generate_content(\n",
        "    model=MODEL_ID,\n",
        "    contents='Quando é a próxima Imersão IA com Google Gemini da Alura?',\n",
        ")\n",
        "\n",
        "# Exibe a resposta na tela\n",
        "display(Markdown(f\"Resposta:\\n {resposta.text}\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "id": "Y9cBAz02xZt9",
        "outputId": "b3300d45-f337-4ac9-8f7f-fba3d9cbfb54"
      },
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "Resposta:\n A Alura não tem uma data fixa para a Imersão IA com Google Gemini. A melhor forma de saber quando será a próxima edição é:\n\n*   **Acompanhar as redes sociais da Alura:** Fique de olho no Instagram, LinkedIn e outros canais onde a Alura costuma divulgar seus eventos e cursos.\n*   **Verificar a página de Imersões da Alura:** Procure na página de Imersões da Alura (geralmente no site principal) se há alguma Imersão IA com Google Gemini programada.\n*   **Assinar a newsletter da Alura:** Assim você recebe informações sobre os próximos cursos e eventos diretamente no seu e-mail."
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Pergunta ao Gemini uma informação utilizando a busca do Google como contexto\n",
        "\n",
        "response = client.models.generate_content(\n",
        "    model=MODEL_ID,\n",
        "    contents='Quando é a próxima Imersão IA com Google Gemini da Alura?',\n",
        "    config={\"tools\": [{\"google_search\": {}}]}\n",
        ")\n",
        "\n",
        "# Exibe a resposta na tela\n",
        "display(Markdown(f\"Resposta:\\n {response.text}\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 64
        },
        "id": "lc2JPA92xbnp",
        "outputId": "e9f1b92e-a9c1-491f-a191-4fcd97743ca6"
      },
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "Resposta:\n A próxima Imersão IA com Google Gemini da Alura acontecerá de 12 a 16 de maio de 2025. As inscrições estão abertas até 11 de maio de 2025. O curso é online, gratuito e não exige pré-requisitos. Ao final, você receberá um certificado Alura + Google e poderá concorrer a prêmios."
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Exibe a busca\n",
        "print(f\"Busca realizada: {response.candidates[0].grounding_metadata.web_search_queries}\")\n",
        "# Exibe as URLs nas quais ele se baseou\n",
        "print(f\"Páginas utilizadas na resposta: {', '.join([site.web.title for site in response.candidates[0].grounding_metadata.grounding_chunks])}\")\n",
        "print()\n",
        "display(HTML(response.candidates[0].grounding_metadata.search_entry_point.rendered_content))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        },
        "id": "6Cg0KNJGMgC5",
        "outputId": "02d03c4f-a31f-4d40-e7df-61f29b7e8c65"
      },
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Busca realizada: ['próxima Imersão IA com Google Gemini da Alura', 'Alura Imersão IA Google Gemini']\n",
            "Páginas utilizadas na resposta: thallesbenicio.com.br, tiktok.com, starten.tech, rodrigostoledo.com, youtube.com, alura.com.br\n",
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<style>\n",
              ".container {\n",
              "  align-items: center;\n",
              "  border-radius: 8px;\n",
              "  display: flex;\n",
              "  font-family: Google Sans, Roboto, sans-serif;\n",
              "  font-size: 14px;\n",
              "  line-height: 20px;\n",
              "  padding: 8px 12px;\n",
              "}\n",
              ".chip {\n",
              "  display: inline-block;\n",
              "  border: solid 1px;\n",
              "  border-radius: 16px;\n",
              "  min-width: 14px;\n",
              "  padding: 5px 16px;\n",
              "  text-align: center;\n",
              "  user-select: none;\n",
              "  margin: 0 8px;\n",
              "  -webkit-tap-highlight-color: transparent;\n",
              "}\n",
              ".carousel {\n",
              "  overflow: auto;\n",
              "  scrollbar-width: none;\n",
              "  white-space: nowrap;\n",
              "  margin-right: -12px;\n",
              "}\n",
              ".headline {\n",
              "  display: flex;\n",
              "  margin-right: 4px;\n",
              "}\n",
              ".gradient-container {\n",
              "  position: relative;\n",
              "}\n",
              ".gradient {\n",
              "  position: absolute;\n",
              "  transform: translate(3px, -9px);\n",
              "  height: 36px;\n",
              "  width: 9px;\n",
              "}\n",
              "@media (prefers-color-scheme: light) {\n",
              "  .container {\n",
              "    background-color: #fafafa;\n",
              "    box-shadow: 0 0 0 1px #0000000f;\n",
              "  }\n",
              "  .headline-label {\n",
              "    color: #1f1f1f;\n",
              "  }\n",
              "  .chip {\n",
              "    background-color: #ffffff;\n",
              "    border-color: #d2d2d2;\n",
              "    color: #5e5e5e;\n",
              "    text-decoration: none;\n",
              "  }\n",
              "  .chip:hover {\n",
              "    background-color: #f2f2f2;\n",
              "  }\n",
              "  .chip:focus {\n",
              "    background-color: #f2f2f2;\n",
              "  }\n",
              "  .chip:active {\n",
              "    background-color: #d8d8d8;\n",
              "    border-color: #b6b6b6;\n",
              "  }\n",
              "  .logo-dark {\n",
              "    display: none;\n",
              "  }\n",
              "  .gradient {\n",
              "    background: linear-gradient(90deg, #fafafa 15%, #fafafa00 100%);\n",
              "  }\n",
              "}\n",
              "@media (prefers-color-scheme: dark) {\n",
              "  .container {\n",
              "    background-color: #1f1f1f;\n",
              "    box-shadow: 0 0 0 1px #ffffff26;\n",
              "  }\n",
              "  .headline-label {\n",
              "    color: #fff;\n",
              "  }\n",
              "  .chip {\n",
              "    background-color: #2c2c2c;\n",
              "    border-color: #3c4043;\n",
              "    color: #fff;\n",
              "    text-decoration: none;\n",
              "  }\n",
              "  .chip:hover {\n",
              "    background-color: #353536;\n",
              "  }\n",
              "  .chip:focus {\n",
              "    background-color: #353536;\n",
              "  }\n",
              "  .chip:active {\n",
              "    background-color: #464849;\n",
              "    border-color: #53575b;\n",
              "  }\n",
              "  .logo-light {\n",
              "    display: none;\n",
              "  }\n",
              "  .gradient {\n",
              "    background: linear-gradient(90deg, #1f1f1f 15%, #1f1f1f00 100%);\n",
              "  }\n",
              "}\n",
              "</style>\n",
              "<div class=\"container\">\n",
              "  <div class=\"headline\">\n",
              "    <svg class=\"logo-light\" width=\"18\" height=\"18\" viewBox=\"9 9 35 35\" fill=\"none\" xmlns=\"http://www.w3.org/2000/svg\">\n",
              "      <path fill-rule=\"evenodd\" clip-rule=\"evenodd\" d=\"M42.8622 27.0064C42.8622 25.7839 42.7525 24.6084 42.5487 23.4799H26.3109V30.1568H35.5897C35.1821 32.3041 33.9596 34.1222 32.1258 35.3448V39.6864H37.7213C40.9814 36.677 42.8622 32.2571 42.8622 27.0064V27.0064Z\" fill=\"#4285F4\"/>\n",
              "      <path fill-rule=\"evenodd\" clip-rule=\"evenodd\" d=\"M26.3109 43.8555C30.9659 43.8555 34.8687 42.3195 37.7213 39.6863L32.1258 35.3447C30.5898 36.3792 28.6306 37.0061 26.3109 37.0061C21.8282 37.0061 18.0195 33.9811 16.6559 29.906H10.9194V34.3573C13.7563 39.9841 19.5712 43.8555 26.3109 43.8555V43.8555Z\" fill=\"#34A853\"/>\n",
              "      <path fill-rule=\"evenodd\" clip-rule=\"evenodd\" d=\"M16.6559 29.8904C16.3111 28.8559 16.1074 27.7588 16.1074 26.6146C16.1074 25.4704 16.3111 24.3733 16.6559 23.3388V18.8875H10.9194C9.74388 21.2072 9.06992 23.8247 9.06992 26.6146C9.06992 29.4045 9.74388 32.022 10.9194 34.3417L15.3864 30.8621L16.6559 29.8904V29.8904Z\" fill=\"#FBBC05\"/>\n",
              "      <path fill-rule=\"evenodd\" clip-rule=\"evenodd\" d=\"M26.3109 16.2386C28.85 16.2386 31.107 17.1164 32.9095 18.8091L37.8466 13.8719C34.853 11.082 30.9659 9.3736 26.3109 9.3736C19.5712 9.3736 13.7563 13.245 10.9194 18.8875L16.6559 23.3388C18.0195 19.2636 21.8282 16.2386 26.3109 16.2386V16.2386Z\" fill=\"#EA4335\"/>\n",
              "    </svg>\n",
              "    <svg class=\"logo-dark\" width=\"18\" height=\"18\" viewBox=\"0 0 48 48\" xmlns=\"http://www.w3.org/2000/svg\">\n",
              "      <circle cx=\"24\" cy=\"23\" fill=\"#FFF\" r=\"22\"/>\n",
              "      <path d=\"M33.76 34.26c2.75-2.56 4.49-6.37 4.49-11.26 0-.89-.08-1.84-.29-3H24.01v5.99h8.03c-.4 2.02-1.5 3.56-3.07 4.56v.75l3.91 2.97h.88z\" fill=\"#4285F4\"/>\n",
              "      <path d=\"M15.58 25.77A8.845 8.845 0 0 0 24 31.86c1.92 0 3.62-.46 4.97-1.31l4.79 3.71C31.14 36.7 27.65 38 24 38c-5.93 0-11.01-3.4-13.45-8.36l.17-1.01 4.06-2.85h.8z\" fill=\"#34A853\"/>\n",
              "      <path d=\"M15.59 20.21a8.864 8.864 0 0 0 0 5.58l-5.03 3.86c-.98-2-1.53-4.25-1.53-6.64 0-2.39.55-4.64 1.53-6.64l1-.22 3.81 2.98.22 1.08z\" fill=\"#FBBC05\"/>\n",
              "      <path d=\"M24 14.14c2.11 0 4.02.75 5.52 1.98l4.36-4.36C31.22 9.43 27.81 8 24 8c-5.93 0-11.01 3.4-13.45 8.36l5.03 3.85A8.86 8.86 0 0 1 24 14.14z\" fill=\"#EA4335\"/>\n",
              "    </svg>\n",
              "    <div class=\"gradient-container\"><div class=\"gradient\"></div></div>\n",
              "  </div>\n",
              "  <div class=\"carousel\">\n",
              "    <a class=\"chip\" href=\"https://vertexaisearch.cloud.google.com/grounding-api-redirect/AbF9wXEbUY696Cbs5DoXB4aRpU10iuHscAeYgU9ZtnQ60PuVVdQLGoiM7CFe9p1GSLjT2G-tDTkQQLaRhfmKvecpf8ibSLYZBskkldiIVDia7pb9_J1HnFxPrjuLzMgBwqz_NVKOPaNsIcZJjtUfE8cBY4UEnp3-9dAYBzig2kJOxAO86rFQjOoO5YC3cJEd4qkwEtCecQI4laO5_TtEDRnZ4PizgMQ0wKl-\">Alura Imersão IA Google Gemini</a>\n",
              "    <a class=\"chip\" href=\"https://vertexaisearch.cloud.google.com/grounding-api-redirect/AbF9wXGcksv0XCPBOG2PBCHOxqB_A9_pcT4Kkwj2fh1RWnsCxpPLHQIdz8gWuVbyxumVP9weIYXkU987AbYkyl7E2rUsIGmySGbdLoeKpcLz_0r5BSKcQxd79mcR1nwDO1Zlcy24WZa4PEN9XjSvQfp4kkyPbVtutx7OOMGgV99Cf-a8d6_bHJfP-A08ikYKZ4DCOOGHXjVQizejHpEIip92E8rav8kpZ6EFuPymRMQnA8-w4wbU6bC4-tmVqoXV\">próxima Imersão IA com Google Gemini da Alura</a>\n",
              "  </div>\n",
              "</div>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Instalar Framework de agentes do Google ################################################\n",
        "!pip install -q google-adk"
      ],
      "metadata": {
        "id": "a1eRPalxEnj7"
      },
      "execution_count": 78,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 80,
      "metadata": {
        "id": "aePV2bdfDeoW"
      },
      "outputs": [],
      "source": [
        "from google.adk.agents import Agent\n",
        "from google.adk.runners import Runner\n",
        "from google.adk.sessions import InMemorySessionService\n",
        "from google.adk.tools import google_search\n",
        "from google.genai import types  # Para criar conteúdos (Content e Part)\n",
        "from datetime import date\n",
        "import textwrap # Para formatar melhor a saída de texto\n",
        "from IPython.display import display, Markdown # Para exibir texto formatado no Colab\n",
        "import requests # Para fazer requisições HTTP\n",
        "import warnings\n",
        "\n",
        "warnings.filterwarnings(\"ignore\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Função auxiliar que envia uma mensagem para um agente via Runner e retorna a resposta final\n",
        "def call_agent(agent: Agent, message_text: str) -> str:\n",
        "    # Cria um serviço de sessão em memória\n",
        "    session_service = InMemorySessionService()\n",
        "    # Cria uma nova sessão (você pode personalizar os IDs conforme necessário)\n",
        "    session = session_service.create_session(app_name=agent.name, user_id=\"user1\", session_id=\"session1\")\n",
        "    # Cria um Runner para o agente\n",
        "    runner = Runner(agent=agent, app_name=agent.name, session_service=session_service)\n",
        "    # Cria o conteúdo da mensagem de entrada\n",
        "    content = types.Content(role=\"user\", parts=[types.Part(text=message_text)])\n",
        "\n",
        "    final_response = \"\"\n",
        "    # Itera assincronamente pelos eventos retornados durante a execução do agente\n",
        "    for event in runner.run(user_id=\"user1\", session_id=\"session1\", new_message=content):\n",
        "        if event.is_final_response():\n",
        "          for part in event.content.parts:\n",
        "            if part.text is not None:\n",
        "              final_response += part.text\n",
        "              final_response += \"\\n\"\n",
        "    return final_response"
      ],
      "metadata": {
        "id": "_xP4lWhsS5ko"
      },
      "execution_count": 67,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Função auxiliar para exibir texto formatado em Markdown no Colab\n",
        "def to_markdown(text):\n",
        "  text = text.replace('•', '  *')\n",
        "  return Markdown(textwrap.indent(text, '> ', predicate=lambda _: True))"
      ],
      "metadata": {
        "id": "8dosiodaxfFR"
      },
      "execution_count": 68,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "##########################################\n",
        "# --- Agente 1: Buscador de Notícias --- #\n",
        "##########################################\n",
        "def agente_buscador(topico, data_de_hoje):\n",
        "    buscador = Agent(\n",
        "        name=\"agente_buscador\",\n",
        "        model=\"gemini-2.0-flash\",\n",
        "        instruction=\"\"\"\n",
        "        Você é parte de um sistema colaborativo de verificação de notícias. Siga rigorosamente as instruções específicas da sua função para analisar o tópico fornecido e contribuir para a determinação da sua veracidade.\n",
        "        Sua função é ser um assistente de pesquisa. A sua tarefa é usar a ferramenta de busca google (google_search) para recuperar as últimas notícias de lançamentos muito relevantes sobre o tópico abaixo.\n",
        "        Priorize fontes jornalísticas reconhecidas e com boa reputação.\n",
        "        Selecione no máximo 5 lançamentos que demonstrem relevância (baseada na cobertura e qualidade da fonte) e sejam os mais atuais possíveis.\n",
        "        Se o tópico não possuir 5 notícias a seu respeito, apresente somente as encontradas. Sem adicionar outras notícias com termos parecidos e que não tenham relação direta com o tópico.\n",
        "        Se o tópico gerar pouca cobertura noticiosa ou reações limitadas, sinalize essa baixa relevância como um possível indicativo para considerar outros tópicos.\n",
        "        Esses lançamentos relevantes devem ser atuais, de no máximo um mês antes da data de hoje.\n",
        "        \"\"\",\n",
        "        description=\"Agente que busca de notícias no Google Search sobre o tópico\",\n",
        "        tools=[google_search]\n",
        "    )\n",
        "\n",
        "    entrada_do_agente_buscador = f\"Tópico: {topico}\\nData de hoje: {data_de_hoje}\"\n",
        "    # Executa o agente\n",
        "    lancamentos_buscados = call_agent(buscador, entrada_do_agente_buscador)\n",
        "    return lancamentos_buscados"
      ],
      "metadata": {
        "id": "o8bqIfi_DyH8"
      },
      "execution_count": 69,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "################################################\n",
        "# --- Agente 2: Verificador de Fontes --- #\n",
        "################################################\n",
        "def agente_verificador_fontes(topico, lancamentos_buscados):\n",
        "    verificador_fontes = Agent(\n",
        "        name=\"agente_verificador_fontes\",\n",
        "        model=\"gemini-2.0-flash\",\n",
        "        # Inserir as instruções do Agente Verificador de Fontes #################################################\n",
        "        instruction=\"\"\"\n",
        "        Você é parte de um sistema colaborativo de verificação de notícias. Siga rigorosamente as instruções específicas da sua função para analisar o tópico fornecido e contribuir para a determinação da sua veracidade.\n",
        "        Sua função é ser um verificador de fontes, especialista em fact-checking.\n",
        "        Para cada fonte principal identificada:\n",
        "        - Determine se o site ou canal é conhecido e geralmente considerado confiável.\n",
        "        - Localize e examine a seção 'Sobre nós' (ou equivalente) para entender a missão, equipe e possíveis vieses do site.\n",
        "        - Verifique se outras fontes confiáveis corroboram as informações apresentadas pela fonte principal. Liste as fontes que confirmam os achados.\n",
        "        \"\"\",\n",
        "        description=\"Agente que verifica as fontes levantadas\",\n",
        "        tools=[google_search]\n",
        "    )\n",
        "\n",
        "    entrada_do_agente_verificador_fontes = f\"Tópico:{topico}\\nLançamentos buscados: {lancamentos_buscados}\"\n",
        "    # Executa o agente\n",
        "    verificacao_fontes = call_agent(verificador_fontes, entrada_do_agente_verificador_fontes)\n",
        "    return verificacao_fontes"
      ],
      "metadata": {
        "id": "y3VO1uo5_ghO"
      },
      "execution_count": 71,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "################################################\n",
        "# --- Agente 3: Verificador de Conteúdo --- #\n",
        "################################################\n",
        "def agente_verificador_conteudo(topico, lancamentos_buscados):\n",
        "    verificador_conteudo = Agent(\n",
        "        name=\"agente_verificador_conteudo\",\n",
        "        model=\"gemini-2.0-flash\",\n",
        "        # Inserir as instruções do Agente Verificador de Conteúdo #################################################\n",
        "        instruction=\"\"\"\n",
        "        Você é parte de um sistema colaborativo de verificação de notícias. Siga rigorosamente as instruções específicas da sua função para analisar o tópico fornecido e contribuir para a determinação da sua veracidade.\n",
        "        Sua função é ser um verificador de conteúdo, especialista em fact-checking.\n",
        "        Examine o conteúdo das notícias e informações relacionadas ao tópico.\n",
        "        Linguagem e Estilo:\n",
        "        - Avalie se há uso de sofismos ou outras técnicas de persuasão manipuladoras.\n",
        "        - Identifique erros de ortografia e gramática que possam indicar falta de profissionalismo ou revisão.\n",
        "        - Distinga claramente entre fatos apresentados e opiniões, verificando se as opiniões são devidamente atribuídas.\n",
        "        Contexto e Evidências:\n",
        "        - Verifique se a data da informação é relevante para o contexto atual.\n",
        "        - Se houver imagens, utilize a busca reversa (Google Imagens) para verificar sua autenticidade e se foram usadas em outros contextos enganosos.\n",
        "        Coerência:\n",
        "        - Avalie a lógica interna do conteúdo e sua coerência com informações de outras fontes.\n",
        "        \"\"\",\n",
        "        description=\"Agente que verifica o conteúdo das notícias levantadas\",\n",
        "        tools=[google_search]\n",
        "    )\n",
        "\n",
        "    entrada_do_agente_verificador_conteudo = f\"Tópico:{topico}\\nLançamentos buscados: {lancamentos_buscados}\"\n",
        "    # Executa o agente\n",
        "    verificacao_conteudo = call_agent(verificador_conteudo, entrada_do_agente_verificador_conteudo)\n",
        "    return verificacao_conteudo"
      ],
      "metadata": {
        "id": "uOqlg2TRLVh1"
      },
      "execution_count": 72,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "##########################################\n",
        "# --- Agente 4: Agência de Fact-Checking --- #\n",
        "##########################################\n",
        "def agente_verificador_fatos(topico, data_de_hoje):\n",
        "    verificador_fatos = Agent(\n",
        "        name=\"agente_verificador_fatos\",\n",
        "        model=\"gemini-2.0-flash\",\n",
        "        instruction=\"\"\"\n",
        "        Você é parte de um sistema colaborativo de verificação de notícias. Siga rigorosamente as instruções específicas da sua função para analisar o tópico fornecido e contribuir para a determinação da sua veracidade.\n",
        "        Sua tarefa é verificar se o tópico/afirmação já foi alvo de checagem por agências de fact-checking confiáveis, através da  busca google (google_search), priorizando as verificações mais recentes sobre o tópico.\n",
        "        As agências de fact-checking a serem consultadas de acordo com o tópico serão as indicadas abaixo:\n",
        "        - No Brasil:\n",
        "          - Aos Fatos;\n",
        "          - Lupa;\n",
        "          - UOL Confere;\n",
        "          - Estadão Verifica;\n",
        "          - Fato ou Fake (G1);\n",
        "          - Boatos.org;\n",
        "          - Agência Pública - Truco no Congresso;\n",
        "          - Comprova;\n",
        "          - E-farsas;\n",
        "          - É isso Mesmo? (O Globo);\n",
        "          - Portal EBC - Checagem;\n",
        "        - Internacionais com atuação ou relevância no Brasil:\n",
        "          - AFP Fact Check;\n",
        "          - Reuters Fact Check;\n",
        "          - Snopes;\n",
        "          - PolitiFact;\n",
        "          - FactCheck.org;\n",
        "        - Organizações e Redes Internacionais:\n",
        "          - International Fact-Checking Network (IFCN);\n",
        "          - European Fact-Checking Standards Network (EFCSN);\n",
        "          - Duke Reporters' Lab;\n",
        "        Informe se o tópico foi encontrado em alguma das agências de fact-checking e qual foi a conclusão dessas agências (verdadeiro, falso, enganoso, etc.).\n",
        "        Se encontrado, cite a fonte da agência de fact-checking e um breve resumo da sua análise.\n",
        "        \"\"\",\n",
        "        description=\"Agente que verifica o que agências de fact-checking dizem a respeito do tópico\",\n",
        "        tools=[google_search]\n",
        "    )\n",
        "\n",
        "    entrada_do_agente_verificador_fatos = f\"Tópico: {topico}\\nData de hoje: {data_de_hoje}\"\n",
        "    # Executa o agente\n",
        "    verificacao_fatos = call_agent(verificador_fatos, entrada_do_agente_verificador_fatos)\n",
        "    return verificacao_fatos"
      ],
      "metadata": {
        "id": "_aTb1SdkLeT6"
      },
      "execution_count": 75,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "################################################\n",
        "# --- Agente 5: Organizador do Resultado da Verificação --- #\n",
        "################################################\n",
        "def agente_organizador_resultado(topico, lancamentos_buscados, verificacao_fontes, verificacao_conteudo, verificacao_fatos):\n",
        "    organizador = Agent(\n",
        "        name=\"agente_organizador_resultado\",\n",
        "        model=\"gemini-2.0-flash\",\n",
        "        # Inserir as instruções do Agente de Resultados #################################################\n",
        "        instruction=\"\"\"\n",
        "        Você é parte de um sistema colaborativo de verificação de notícias. Siga rigorosamente as instruções específicas da sua função para analisar o tópico fornecido e contribuir para a determinação da sua veracidade.\n",
        "        Sua função é organizar os resultados com base nas análises dos outros agentes sobre o tópico, e determinar a veracidade da informação.\n",
        "        Apresente um veredicto claro: Verdadeiro, Falso, Enganoso, Insustentável, etc.\n",
        "        Justifique sua conclusão de forma concisa, utilizando as evidências e os resultados fornecidos pelos outros agentes (agente_buscador, agente_verificador_fontes, agente_verificador_conteudo e agente_verificador_fatos).\n",
        "        Liste as fontes mais relevantes (sites de notícias confiáveis, agências de fact-checking) que sustentam sua conclusão.\n",
        "        \"\"\",\n",
        "        description=\"Agente que organiza os resultados da verificação\",\n",
        "        tools=[google_search]\n",
        "    )\n",
        "\n",
        "    entrada_do_agente_organizador_resultado = f\"Tópico:{topico}\\nLançamentos buscados:{lancamentos_buscados}\\nVerificação fontes:{verificacao_fontes}\\nVerificação conteúdo:{verificacao_conteudo}\\nVerificação fatos:{verificacao_fatos}\"\n",
        "    # Executa o agente\n",
        "    resultado = call_agent(organizador,  entrada_do_agente_organizador_resultado)\n",
        "    return resultado"
      ],
      "metadata": {
        "id": "Zsryvj_FS6N7"
      },
      "execution_count": 76,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "data_de_hoje = date.today().strftime(\"%d/%m/%Y\")\n",
        "\n",
        "print(\"🚀 Iniciando o Sistema de Verificação de Fatos com 5 Agentes 🚀\")\n",
        "\n",
        "# --- Obter o Tópico do Usuário ---\n",
        "topico = input(\"❓ Por favor, digite o TÓPICO sobre o qual você quer saber a veracidade: \")\n",
        "\n",
        "# Inserir lógica do sistema de agentes ################################################\n",
        "if not topico:\n",
        "    print(\"Você esqueceu de digitar o tópico!\")\n",
        "else:\n",
        "    print(f\"Maravilha! Vamos pesquisar sobre a veracidade a respeito de {topico}\")\n",
        "\n",
        "    lancamentos_buscados = agente_buscador(topico, data_de_hoje)\n",
        "    print(\"\\n--- 📝 Resultado do Agente 1 (Buscador de Notícias) ---\\n\")\n",
        "    display(to_markdown(lancamentos_buscados))\n",
        "    print(\"--------------------------------------------------------------\")\n",
        "\n",
        "    verificacao_fontes = agente_verificador_fontes(topico, lancamentos_buscados)\n",
        "    print(\"\\n--- 📝 Resultado do Agente 2 (Verificador de Fontes) ---\\n\")\n",
        "    display(to_markdown(verificacao_fontes))\n",
        "    print(\"--------------------------------------------------------------\")\n",
        "\n",
        "    verificacao_conteudo = agente_verificador_conteudo(topico, lancamentos_buscados)\n",
        "    print(\"\\n--- 📝 Resultado do Agente 3 (Verificador de Conteúdo) ---\\n\")\n",
        "    display(to_markdown(verificacao_conteudo))\n",
        "    print(\"--------------------------------------------------------------\")\n",
        "\n",
        "    verificacao_fatos = agente_verificador_fatos(topico, data_de_hoje)\n",
        "    print(\"\\n--- 📝 Resultado do Agente 4 (Agências de Fact-Checking) ---\\n\")\n",
        "    display(to_markdown(verificacao_fatos))\n",
        "    print(\"--------------------------------------------------------------\")\n",
        "\n",
        "    resultado = agente_organizador_resultado(topico, lancamentos_buscados, verificacao_fontes, verificacao_conteudo, verificacao_fatos)\n",
        "    print(\"\\n--- 📝 Resultado do Agente 5 (Organizador do Resultado da Verificação) ---\\n\")\n",
        "    display(to_markdown(resultado))\n",
        "    print(\"--------------------------------------------------------------\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "6xzI6LKzxxnN",
        "outputId": "a952971b-3bf2-419d-9754-6bf035448d75"
      },
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🚀 Iniciando o Sistema de Verificação de Fatos com 5 Agentes 🚀\n",
            "❓ Por favor, digite o TÓPICO sobre o qual você quer saber a veracidade: terra plana\n",
            "Maravilha! Vamos pesquisar sobre a veracidade a respeito de terra plana\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Exception in thread Thread-105 (_asyncio_thread_main):\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.11/threading.py\", line 1045, in _bootstrap_inner\n",
            "    self.run()\n",
            "  File \"/usr/lib/python3.11/threading.py\", line 982, in run\n",
            "    self._target(*self._args, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/google/adk/runners.py\", line 138, in _asyncio_thread_main\n",
            "    asyncio.run(_invoke_run_async())\n",
            "  File \"/usr/lib/python3.11/asyncio/runners.py\", line 190, in run\n",
            "    return runner.run(main)\n",
            "           ^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/lib/python3.11/asyncio/runners.py\", line 118, in run\n",
            "    return self._loop.run_until_complete(task)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/lib/python3.11/asyncio/base_events.py\", line 654, in run_until_complete\n",
            "    return future.result()\n",
            "           ^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/google/adk/runners.py\", line 126, in _invoke_run_async\n",
            "    async for event in self.run_async(\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/google/adk/runners.py\", line 197, in run_async\n",
            "    async for event in invocation_context.agent.run_async(invocation_context):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/google/adk/agents/base_agent.py\", line 133, in run_async\n",
            "    async for event in self._run_async_impl(ctx):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/google/adk/agents/llm_agent.py\", line 246, in _run_async_impl\n",
            "    async for event in self._llm_flow.run_async(ctx):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/google/adk/flows/llm_flows/base_llm_flow.py\", line 243, in run_async\n",
            "    async for event in self._run_one_step_async(invocation_context):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/google/adk/flows/llm_flows/base_llm_flow.py\", line 268, in _run_one_step_async\n",
            "    async for llm_response in self._call_llm_async(\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/google/adk/flows/llm_flows/base_llm_flow.py\", line 483, in _call_llm_async\n",
            "    async for llm_response in llm.generate_content_async(\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/google/adk/models/google_llm.py\", line 140, in generate_content_async\n",
            "    response = await self.api_client.aio.models.generate_content(\n",
            "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/google/genai/models.py\", line 6672, in generate_content\n",
            "    response = await self._generate_content(\n",
            "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/google/genai/models.py\", line 5674, in _generate_content\n",
            "    response_dict = await self._api_client.async_request(\n",
            "                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/google/genai/_api_client.py\", line 789, in async_request\n",
            "    result = await self._async_request(http_request=http_request, stream=False)\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/google/genai/_api_client.py\", line 733, in _async_request\n",
            "    await errors.APIError.raise_for_async_response(response)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/google/genai/errors.py\", line 131, in raise_for_async_response\n",
            "    raise ServerError(status_code, response_json, response)\n",
            "google.genai.errors.ServerError: 503 UNAVAILABLE. {'error': {'code': 503, 'message': 'The model is overloaded. Please try again later.', 'status': 'UNAVAILABLE'}}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- 📝 Resultado do Agente 1 (Buscador de Notícias) ---\n",
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": ""
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Exception in thread Thread-107 (_asyncio_thread_main):\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.11/threading.py\", line 1045, in _bootstrap_inner\n",
            "    self.run()\n",
            "  File \"/usr/lib/python3.11/threading.py\", line 982, in run\n",
            "    self._target(*self._args, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/google/adk/runners.py\", line 138, in _asyncio_thread_main\n",
            "    asyncio.run(_invoke_run_async())\n",
            "  File \"/usr/lib/python3.11/asyncio/runners.py\", line 190, in run\n",
            "    return runner.run(main)\n",
            "           ^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/lib/python3.11/asyncio/runners.py\", line 118, in run\n",
            "    return self._loop.run_until_complete(task)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/lib/python3.11/asyncio/base_events.py\", line 654, in run_until_complete\n",
            "    return future.result()\n",
            "           ^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/google/adk/runners.py\", line 126, in _invoke_run_async\n",
            "    async for event in self.run_async(\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/google/adk/runners.py\", line 197, in run_async\n",
            "    async for event in invocation_context.agent.run_async(invocation_context):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/google/adk/agents/base_agent.py\", line 133, in run_async\n",
            "    async for event in self._run_async_impl(ctx):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/google/adk/agents/llm_agent.py\", line 246, in _run_async_impl\n",
            "    async for event in self._llm_flow.run_async(ctx):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/google/adk/flows/llm_flows/base_llm_flow.py\", line 243, in run_async\n",
            "    async for event in self._run_one_step_async(invocation_context):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/google/adk/flows/llm_flows/base_llm_flow.py\", line 268, in _run_one_step_async\n",
            "    async for llm_response in self._call_llm_async(\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/google/adk/flows/llm_flows/base_llm_flow.py\", line 483, in _call_llm_async\n",
            "    async for llm_response in llm.generate_content_async(\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/google/adk/models/google_llm.py\", line 140, in generate_content_async\n",
            "    response = await self.api_client.aio.models.generate_content(\n",
            "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/google/genai/models.py\", line 6672, in generate_content\n",
            "    response = await self._generate_content(\n",
            "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/google/genai/models.py\", line 5674, in _generate_content\n",
            "    response_dict = await self._api_client.async_request(\n",
            "                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/google/genai/_api_client.py\", line 789, in async_request\n",
            "    result = await self._async_request(http_request=http_request, stream=False)\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/google/genai/_api_client.py\", line 733, in _async_request\n",
            "    await errors.APIError.raise_for_async_response(response)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/google/genai/errors.py\", line 131, in raise_for_async_response\n",
            "    raise ServerError(status_code, response_json, response)\n",
            "google.genai.errors.ServerError: 503 UNAVAILABLE. {'error': {'code': 503, 'message': 'The model is overloaded. Please try again later.', 'status': 'UNAVAILABLE'}}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- 📝 Resultado do Agente 2 (Verificador de Fontes) ---\n",
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": ""
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "ERROR:asyncio:Task exception was never retrieved\n",
            "future: <Task finished name='Task-302' coro=<AsyncClient.aclose() done, defined at /usr/local/lib/python3.11/dist-packages/httpx/_client.py:1978> exception=RuntimeError('Event loop is closed')>\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/httpx/_client.py\", line 1985, in aclose\n",
            "    await self._transport.aclose()\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/httpx/_transports/default.py\", line 406, in aclose\n",
            "    await self._pool.aclose()\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/httpcore/_async/connection_pool.py\", line 353, in aclose\n",
            "    await self._close_connections(closing_connections)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/httpcore/_async/connection_pool.py\", line 345, in _close_connections\n",
            "    await connection.aclose()\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/httpcore/_async/connection.py\", line 173, in aclose\n",
            "    await self._connection.aclose()\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/httpcore/_async/http11.py\", line 258, in aclose\n",
            "    await self._network_stream.aclose()\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/httpcore/_backends/anyio.py\", line 53, in aclose\n",
            "    await self._stream.aclose()\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/anyio/streams/tls.py\", line 216, in aclose\n",
            "    await self.transport_stream.aclose()\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/anyio/_backends/_asyncio.py\", line 1314, in aclose\n",
            "    self._transport.close()\n",
            "  File \"/usr/lib/python3.11/asyncio/selector_events.py\", line 864, in close\n",
            "    self._loop.call_soon(self._call_connection_lost, None)\n",
            "  File \"/usr/lib/python3.11/asyncio/base_events.py\", line 762, in call_soon\n",
            "    self._check_closed()\n",
            "  File \"/usr/lib/python3.11/asyncio/base_events.py\", line 520, in _check_closed\n",
            "    raise RuntimeError('Event loop is closed')\n",
            "RuntimeError: Event loop is closed\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Exception in thread Thread-109 (_asyncio_thread_main):\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.11/threading.py\", line 1045, in _bootstrap_inner\n",
            "    self.run()\n",
            "  File \"/usr/lib/python3.11/threading.py\", line 982, in run\n",
            "    self._target(*self._args, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/google/adk/runners.py\", line 138, in _asyncio_thread_main\n",
            "    asyncio.run(_invoke_run_async())\n",
            "  File \"/usr/lib/python3.11/asyncio/runners.py\", line 190, in run\n",
            "    return runner.run(main)\n",
            "           ^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/lib/python3.11/asyncio/runners.py\", line 118, in run\n",
            "    return self._loop.run_until_complete(task)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/lib/python3.11/asyncio/base_events.py\", line 654, in run_until_complete\n",
            "    return future.result()\n",
            "           ^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/google/adk/runners.py\", line 126, in _invoke_run_async\n",
            "    async for event in self.run_async(\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/google/adk/runners.py\", line 197, in run_async\n",
            "    async for event in invocation_context.agent.run_async(invocation_context):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/google/adk/agents/base_agent.py\", line 133, in run_async\n",
            "    async for event in self._run_async_impl(ctx):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/google/adk/agents/llm_agent.py\", line 246, in _run_async_impl\n",
            "    async for event in self._llm_flow.run_async(ctx):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/google/adk/flows/llm_flows/base_llm_flow.py\", line 243, in run_async\n",
            "    async for event in self._run_one_step_async(invocation_context):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/google/adk/flows/llm_flows/base_llm_flow.py\", line 268, in _run_one_step_async\n",
            "    async for llm_response in self._call_llm_async(\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/google/adk/flows/llm_flows/base_llm_flow.py\", line 483, in _call_llm_async\n",
            "    async for llm_response in llm.generate_content_async(\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/google/adk/models/google_llm.py\", line 140, in generate_content_async\n",
            "    response = await self.api_client.aio.models.generate_content(\n",
            "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/google/genai/models.py\", line 6672, in generate_content\n",
            "    response = await self._generate_content(\n",
            "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/google/genai/models.py\", line 5674, in _generate_content\n",
            "    response_dict = await self._api_client.async_request(\n",
            "                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/google/genai/_api_client.py\", line 789, in async_request\n",
            "    result = await self._async_request(http_request=http_request, stream=False)\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/google/genai/_api_client.py\", line 733, in _async_request\n",
            "    await errors.APIError.raise_for_async_response(response)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/google/genai/errors.py\", line 131, in raise_for_async_response\n",
            "    raise ServerError(status_code, response_json, response)\n",
            "google.genai.errors.ServerError: 503 UNAVAILABLE. {'error': {'code': 503, 'message': 'The model is overloaded. Please try again later.', 'status': 'UNAVAILABLE'}}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- 📝 Resultado do Agente 3 (Verificador de Conteúdo) ---\n",
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": ""
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Exception in thread Thread-111 (_asyncio_thread_main):\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.11/threading.py\", line 1045, in _bootstrap_inner\n",
            "    self.run()\n",
            "  File \"/usr/lib/python3.11/threading.py\", line 982, in run\n",
            "    self._target(*self._args, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/google/adk/runners.py\", line 138, in _asyncio_thread_main\n",
            "    asyncio.run(_invoke_run_async())\n",
            "  File \"/usr/lib/python3.11/asyncio/runners.py\", line 190, in run\n",
            "    return runner.run(main)\n",
            "           ^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/lib/python3.11/asyncio/runners.py\", line 118, in run\n",
            "    return self._loop.run_until_complete(task)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/lib/python3.11/asyncio/base_events.py\", line 654, in run_until_complete\n",
            "    return future.result()\n",
            "           ^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/google/adk/runners.py\", line 126, in _invoke_run_async\n",
            "    async for event in self.run_async(\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/google/adk/runners.py\", line 197, in run_async\n",
            "    async for event in invocation_context.agent.run_async(invocation_context):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/google/adk/agents/base_agent.py\", line 133, in run_async\n",
            "    async for event in self._run_async_impl(ctx):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/google/adk/agents/llm_agent.py\", line 246, in _run_async_impl\n",
            "    async for event in self._llm_flow.run_async(ctx):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/google/adk/flows/llm_flows/base_llm_flow.py\", line 243, in run_async\n",
            "    async for event in self._run_one_step_async(invocation_context):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/google/adk/flows/llm_flows/base_llm_flow.py\", line 268, in _run_one_step_async\n",
            "    async for llm_response in self._call_llm_async(\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/google/adk/flows/llm_flows/base_llm_flow.py\", line 483, in _call_llm_async\n",
            "    async for llm_response in llm.generate_content_async(\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/google/adk/models/google_llm.py\", line 140, in generate_content_async\n",
            "    response = await self.api_client.aio.models.generate_content(\n",
            "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/google/genai/models.py\", line 6672, in generate_content\n",
            "    response = await self._generate_content(\n",
            "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/google/genai/models.py\", line 5674, in _generate_content\n",
            "    response_dict = await self._api_client.async_request(\n",
            "                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/google/genai/_api_client.py\", line 789, in async_request\n",
            "    result = await self._async_request(http_request=http_request, stream=False)\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/google/genai/_api_client.py\", line 733, in _async_request\n",
            "    await errors.APIError.raise_for_async_response(response)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/google/genai/errors.py\", line 131, in raise_for_async_response\n",
            "    raise ServerError(status_code, response_json, response)\n",
            "google.genai.errors.ServerError: 503 UNAVAILABLE. {'error': {'code': 503, 'message': 'The model is overloaded. Please try again later.', 'status': 'UNAVAILABLE'}}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- 📝 Resultado do Agente 4 (Agências de Fact-Checking) ---\n",
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": ""
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "ERROR:asyncio:Task exception was never retrieved\n",
            "future: <Task finished name='Task-313' coro=<AsyncClient.aclose() done, defined at /usr/local/lib/python3.11/dist-packages/httpx/_client.py:1978> exception=RuntimeError('Event loop is closed')>\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/httpx/_client.py\", line 1985, in aclose\n",
            "    await self._transport.aclose()\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/httpx/_transports/default.py\", line 406, in aclose\n",
            "    await self._pool.aclose()\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/httpcore/_async/connection_pool.py\", line 353, in aclose\n",
            "    await self._close_connections(closing_connections)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/httpcore/_async/connection_pool.py\", line 345, in _close_connections\n",
            "    await connection.aclose()\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/httpcore/_async/connection.py\", line 173, in aclose\n",
            "    await self._connection.aclose()\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/httpcore/_async/http11.py\", line 258, in aclose\n",
            "    await self._network_stream.aclose()\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/httpcore/_backends/anyio.py\", line 53, in aclose\n",
            "    await self._stream.aclose()\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/anyio/streams/tls.py\", line 216, in aclose\n",
            "    await self.transport_stream.aclose()\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/anyio/_backends/_asyncio.py\", line 1314, in aclose\n",
            "    self._transport.close()\n",
            "  File \"/usr/lib/python3.11/asyncio/selector_events.py\", line 864, in close\n",
            "    self._loop.call_soon(self._call_connection_lost, None)\n",
            "  File \"/usr/lib/python3.11/asyncio/base_events.py\", line 762, in call_soon\n",
            "    self._check_closed()\n",
            "  File \"/usr/lib/python3.11/asyncio/base_events.py\", line 520, in _check_closed\n",
            "    raise RuntimeError('Event loop is closed')\n",
            "RuntimeError: Event loop is closed\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Exception in thread Thread-113 (_asyncio_thread_main):\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.11/threading.py\", line 1045, in _bootstrap_inner\n",
            "    self.run()\n",
            "  File \"/usr/lib/python3.11/threading.py\", line 982, in run\n",
            "    self._target(*self._args, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/google/adk/runners.py\", line 138, in _asyncio_thread_main\n",
            "    asyncio.run(_invoke_run_async())\n",
            "  File \"/usr/lib/python3.11/asyncio/runners.py\", line 190, in run\n",
            "    return runner.run(main)\n",
            "           ^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/lib/python3.11/asyncio/runners.py\", line 118, in run\n",
            "    return self._loop.run_until_complete(task)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/lib/python3.11/asyncio/base_events.py\", line 654, in run_until_complete\n",
            "    return future.result()\n",
            "           ^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/google/adk/runners.py\", line 126, in _invoke_run_async\n",
            "    async for event in self.run_async(\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/google/adk/runners.py\", line 197, in run_async\n",
            "    async for event in invocation_context.agent.run_async(invocation_context):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/google/adk/agents/base_agent.py\", line 133, in run_async\n",
            "    async for event in self._run_async_impl(ctx):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/google/adk/agents/llm_agent.py\", line 246, in _run_async_impl\n",
            "    async for event in self._llm_flow.run_async(ctx):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/google/adk/flows/llm_flows/base_llm_flow.py\", line 243, in run_async\n",
            "    async for event in self._run_one_step_async(invocation_context):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/google/adk/flows/llm_flows/base_llm_flow.py\", line 268, in _run_one_step_async\n",
            "    async for llm_response in self._call_llm_async(\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/google/adk/flows/llm_flows/base_llm_flow.py\", line 483, in _call_llm_async\n",
            "    async for llm_response in llm.generate_content_async(\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/google/adk/models/google_llm.py\", line 140, in generate_content_async\n",
            "    response = await self.api_client.aio.models.generate_content(\n",
            "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/google/genai/models.py\", line 6672, in generate_content\n",
            "    response = await self._generate_content(\n",
            "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/google/genai/models.py\", line 5674, in _generate_content\n",
            "    response_dict = await self._api_client.async_request(\n",
            "                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/google/genai/_api_client.py\", line 789, in async_request\n",
            "    result = await self._async_request(http_request=http_request, stream=False)\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/google/genai/_api_client.py\", line 733, in _async_request\n",
            "    await errors.APIError.raise_for_async_response(response)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/google/genai/errors.py\", line 131, in raise_for_async_response\n",
            "    raise ServerError(status_code, response_json, response)\n",
            "google.genai.errors.ServerError: 503 UNAVAILABLE. {'error': {'code': 503, 'message': 'The model is overloaded. Please try again later.', 'status': 'UNAVAILABLE'}}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- 📝 Resultado do Agente 5 (Organizador do Resultado da Verificação) ---\n",
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": ""
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--------------------------------------------------------------\n"
          ]
        }
      ]
    }
  ]
}